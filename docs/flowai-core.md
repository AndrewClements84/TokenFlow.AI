# ðŸ§  Flow.AI.Core Integration

TokenFlow.AI now integrates directly with the shared **Flow.AI.Core** framework, forming the engine layer of the **Flow.AI ecosystem**.

---

## âœ… Purpose

The Flow.AI.Core integration standardizes how tokenization and cost estimation are shared across all Flow.AI ecosystem projects, including:

- **PromptStream.AI** â€” prompt composition and validation toolkit  
- **DataFlow.AI** â€” structured AI data pipelines  
- **ChatFlow.AI** â€” conversational orchestration framework  
- **ReasonFlow.AI** â€” reasoning and multi-step tool orchestration  

---

## ðŸ”Œ Example Usage

```csharp
using Flow.AI.Core.Interfaces;
using TokenFlow.AI.Integration;

ITokenFlowProvider provider = new TokenFlowProvider("gpt-4o-mini");
int tokens = provider.CountTokens("gpt-4o-mini", "Hello Flow.AI!");
Console.WriteLine($"Token count: {tokens}");
```

This enables unified token counting, cost estimation, and analytics across all Flow.AI projects.

---

## ðŸ§© Core Interfaces

| Interface | Description |
|------------|--------------|
| `ITokenFlowProvider` | Main integration interface for token and cost analysis |
| `IModelRegistry` | Provides centralized access to model configurations |
| `ICostEstimator` | Computes cost based on token usage and model pricing |
| `ITokenizer` | Defines tokenizer behavior per model family |

---

## ðŸ§± Architecture Overview

```
+---------------------+
|     Flow.AI.Core    |  â† Shared interfaces and models
+----------+----------+
           |
           v
+---------------------+
|    TokenFlow.AI     |  â† Engine layer for tokenization & costing
+----------+----------+
           |
           v
+---------------------+
|   PromptStream.AI   |  â† Cockpit layer for prompt orchestration
+---------------------+
```

---

> ðŸ”— TokenFlow.AI serves as the **engine** of the Flow.AI ecosystem â€” powering token counting, chunking, and cost tracking across all higher-level modules.
